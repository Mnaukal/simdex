# This baseline configuration uses duration predictor with oracle that can guess the exact duration of a job.
# The oracle is implemented by cheating, the estimate is taken from job.duration which should
# not be accessed in dispatching in regular experiments.
# The purpose of this configuration is to measure performance of the theoretical optimum as a reference point.
# For the dispatching, a RL algorithm (Deep Q-Network) is used.

# Workers could be either a number or a list that explicitly states a collection of attributes
# If only a number is given, the workers are initialized with no attributes at the beginning.
workers:
  - active: true
  - active: true
  - active: true
  - active: true

# Dispatcher component: either a string (fully qualified class name) or a collection with { class, args }
# where class is fully qualified class name and args is list or dict holding constructor arguments.
# The class should implement the `AbstractDispatcher` interface
dispatcher: dispatchers.WorkerSelectorDispatcher

# Duration predictor: same format as the dispatcher.
# The class should implement the `AbstractDurationPredictor`
duration_predictor: duration_predictors.oracle_duration_predictor.OracleDurationPredictor

# Worker selector: same format as the dispatcher.
# The class should implement the `AbstractWorkerSelector` interface
# Detailed description of the architecture of the `QNetworkWorkerSelector` is available in the paper.
worker_selector:
  class: worker_selectors.q_network_worker_selector.QNetworkWorkerSelector
  args:
    # inference -- epsilon-greedy action selecting with linear interpolation of epsilon
    epsilon_initial: 0.3
    epsilon_final: 0.001
    epsilon_final_after_jobs: 25_000
    # training
    layer_widths: [ 70 ]  # each value represents a width of one hidden layer
    replay_buffer_size: 100_000  # the number of transitions saved in the replay buffer
    gamma: 0.8  # discount factor for the Q-learning
    training_interval: 10  # number of jobs between training of the Q network
    batch_size: 1000  # number of transitions used for each training

period: 604800  # in seconds, how often a periodic monitoring is invoked. In `QNetworkWorkerSelector`, the target network is updated periodically.

# list of metric components (each one is in the same format as dispatcher)
metrics:
  - metrics.default.JobDelayMetricsCollector
  - metrics.quantile.JobDelayQuantilesCollector
  - class: metrics.user_experience.UserExperienceMetricsCollectorWithHistory
    args:
      ref_jobs: "@@ref_jobs"
      thresholds: [ 1.5, 3.0 ]
#      history_step: 10_000
      history_step: 100_000
#      print_progress: True
