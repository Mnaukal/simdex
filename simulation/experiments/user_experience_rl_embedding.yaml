# This configuration uses a neural-network regression estimator for the duration predictor.
# The NN is trained in batches of incoming jobs as the simulation progresses.
# Before the simulation starts, the embedding layer is trained on the appropriate data which
# can be generated using the `/data/exercise_tlgroup.py` script.
# For the dispatching, a RL algorithm (Deep Q-Network) is used.

# Workers could be either a number or a list that explicitly states a collection of attributes
# If only a number is given, the workers are initialized with no attributes at the beginning.
workers:
  - active: true
  - active: true
  - active: true
  - active: true

# Dispatcher component: either a string (fully qualified class name) or a collection with { class, args }
# where class is fully qualified class name and args is list or dict holding constructor arguments.
# The class should implement the `AbstractDispatcher` interface
dispatcher: dispatchers.WorkerSelectorDispatcher

# Worker selector: same format as the dispatcher.
# The class should implement the `AbstractWorkerSelector` interface
# Detailed description of the architecture of the `QNetworkWorkerSelector` is available in the paper.
worker_selector:
  class: worker_selectors.q_network_worker_selector.QNetworkWorkerSelector
  args:
    # inference -- epsilon-greedy action selecting with linear interpolation of epsilon
    epsilon_initial: 0.3
    epsilon_final: 0.001
    epsilon_final_after_jobs: 25_000
    # training
    layer_widths: [ 70 ]  # each value represents a width of one hidden layer
    replay_buffer_size: 100_000  # the number of transitions saved in the replay buffer
    gamma: 0.8  # discount factor for the Q-learning
    training_interval: 10  # number of jobs between training of the Q network
    batch_size: 1000  # number of transitions used for each training

# Duration predictor: same format as the dispatcher.
# The class should implement the `AbstractDurationPredictor` interface.
# Detailed description of the architecture of the `NNDurationPredictor` is available in the paper.
duration_predictor:
  class: duration_predictors.nn_embedding_duration_predictor.NNEmbeddingDurationPredictor
  args:
    layer_widths: [ 512, 256 ]  # each value represents a width of one hidden layer
    training_interval: 500  # how often to train (in number of jobs)
    batch_size: 1000  # training batch size (most recent jobs)
    training_epochs: 5  # number of epochs in each training
    hash_converters: "@@hash_converters"
    embedding_training_data: "../data/release02-2023-01-04/exercise_tlgroup.csv"  # embeddings training data generated by the `/data/exercise_tlgroup.py` script
    embedding_dim: 100  # size of the embeddings
    embedding_batch_size: 5000  # batch size for embeddings training
    embedding_training_epochs: 100  # number of epochs to train the embeddings

period: 604800  # in seconds, how often a periodic monitoring is invoked. In `QNetworkWorkerSelector`, the target network is updated periodically.

# list of metric components (each one is in the same format as dispatcher)
metrics:
  - metrics.default.JobDelayMetricsCollector
  - metrics.quantile.JobDelayQuantilesCollector
  - class: metrics.user_experience.UserExperienceMetricsCollectorWithHistory
    args:
      ref_jobs: "@@ref_jobs"
      thresholds: [ 1.5, 3.0 ]
#      history_step: 10_000
      history_step: 100_000
#      print_progress: True
